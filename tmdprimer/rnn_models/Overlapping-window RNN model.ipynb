{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification with Neural Networks\n",
    "## Overlapping-window RNN model\n",
    "\n",
    "Overlapping-window RNN model will get as input sliding time windows of a specific pre-defined length from our sequences. Each window will have a label associated with it â€“ **the label of the last timestep in a window**.\n",
    "\n",
    "Window size is a hyper-parameter that will define how long in the past the model will look. This will depend on the specific task you are trying to solve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import altair as alt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tmdprimer.datagen import generate_sample, Dataset, Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a shallow RNN architecture with just one recurrent layer and one output dense unit. But that should be enough for our case given simplicity of our data.\n",
    "\n",
    "The learning rate is adjusted with a schedule for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_rnn_model():\n",
    "    rnn_model = tf.keras.Sequential(\n",
    "        [\n",
    "            # return_sequences is False now since we are trying to predict last y in a window\n",
    "            tf.keras.layers.GRU(8, return_sequences=False),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ]\n",
    "    )\n",
    "    rnn_model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Nadam(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset needs to be adapted for this model. So I added the `to_numpy_windows()` and `to_window_tfds()` functions to our classes to produce those sliding windows from our data. Let me know if it's possible to do it using the `window()` function on `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  ]\n",
      " [0.05]\n",
      " [0.1 ]\n",
      " [0.15]\n",
      " [0.2 ]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.generate(train_outlier_prob=0, n_samples=5)\n",
    "for x, y in dataset.to_window_tfds(window_size=5):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rnn = []\n",
    "for window_size in (5, 10, 50):\n",
    "    for outlier_prob in (0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0):\n",
    "        print(f\"Training for outlier probability: {outlier_prob}, window size: {window_size}\")\n",
    "        dataset = Dataset.generate(train_outlier_prob=outlier_prob, n_samples=100)\n",
    "\n",
    "        model = get_rnn_model()\n",
    "\n",
    "        model.fit(\n",
    "            # we need larger batch sized here since we have many small windows\n",
    "            x=dataset.to_window_tfds(window_size=window_size).batch(200),\n",
    "            epochs=5,\n",
    "            verbose=0\n",
    "        )\n",
    "        test_dataset = Dataset.generate(train_outlier_prob=outlier_prob, n_samples=20)\n",
    "        res = model.evaluate(dataset.to_window_tfds(window_size=window_size).batch(200), verbose=0)\n",
    "        data_rnn.append({'outlier_prob': outlier_prob, 'accuracy': res[1], 'window_size': window_size})\n",
    "    \n",
    "df_rnn = pd.DataFrame(data_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-0bf7ae0bd5a34c0ca8fc859455a69e41\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0bf7ae0bd5a34c0ca8fc859455a69e41\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0bf7ae0bd5a34c0ca8fc859455a69e41\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-37e6fbbcfa4ad1df2fc75def4176883e\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"window_size\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"outlier_prob\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-37e6fbbcfa4ad1df2fc75def4176883e\": [{\"outlier_prob\": 0.01, \"accuracy\": 0.9647444486618042, \"window_size\": 5}, {\"outlier_prob\": 0.05, \"accuracy\": 0.9654725193977356, \"window_size\": 5}, {\"outlier_prob\": 0.1, \"accuracy\": 0.9641252160072327, \"window_size\": 5}, {\"outlier_prob\": 0.2, \"accuracy\": 0.9627902507781982, \"window_size\": 5}, {\"outlier_prob\": 0.3, \"accuracy\": 0.9639808535575867, \"window_size\": 5}, {\"outlier_prob\": 0.4, \"accuracy\": 0.9567490816116333, \"window_size\": 5}, {\"outlier_prob\": 0.5, \"accuracy\": 0.9417595267295837, \"window_size\": 5}, {\"outlier_prob\": 0.6, \"accuracy\": 0.9167448282241821, \"window_size\": 5}, {\"outlier_prob\": 0.7, \"accuracy\": 0.881303071975708, \"window_size\": 5}, {\"outlier_prob\": 0.8, \"accuracy\": 0.8081552982330322, \"window_size\": 5}, {\"outlier_prob\": 0.9, \"accuracy\": 0.6895045638084412, \"window_size\": 5}, {\"outlier_prob\": 1.0, \"accuracy\": 0.4999476373195648, \"window_size\": 5}, {\"outlier_prob\": 0.01, \"accuracy\": 0.9887657761573792, \"window_size\": 10}, {\"outlier_prob\": 0.05, \"accuracy\": 0.9889034032821655, \"window_size\": 10}, {\"outlier_prob\": 0.1, \"accuracy\": 0.9883726835250854, \"window_size\": 10}, {\"outlier_prob\": 0.2, \"accuracy\": 0.9876801371574402, \"window_size\": 10}, {\"outlier_prob\": 0.3, \"accuracy\": 0.9846001267433167, \"window_size\": 10}, {\"outlier_prob\": 0.4, \"accuracy\": 0.9809227585792542, \"window_size\": 10}, {\"outlier_prob\": 0.5, \"accuracy\": 0.9711334705352783, \"window_size\": 10}, {\"outlier_prob\": 0.6, \"accuracy\": 0.9718270897865295, \"window_size\": 10}, {\"outlier_prob\": 0.7, \"accuracy\": 0.9511397480964661, \"window_size\": 10}, {\"outlier_prob\": 0.8, \"accuracy\": 0.9049999713897705, \"window_size\": 10}, {\"outlier_prob\": 0.9, \"accuracy\": 0.7949773073196411, \"window_size\": 10}, {\"outlier_prob\": 1.0, \"accuracy\": 0.5006648302078247, \"window_size\": 10}, {\"outlier_prob\": 0.01, \"accuracy\": 0.987673282623291, \"window_size\": 50}, {\"outlier_prob\": 0.05, \"accuracy\": 0.9861581325531006, \"window_size\": 50}, {\"outlier_prob\": 0.1, \"accuracy\": 0.9854450821876526, \"window_size\": 50}, {\"outlier_prob\": 0.2, \"accuracy\": 0.9858614802360535, \"window_size\": 50}, {\"outlier_prob\": 0.3, \"accuracy\": 0.9852988123893738, \"window_size\": 50}, {\"outlier_prob\": 0.4, \"accuracy\": 0.9832460880279541, \"window_size\": 50}, {\"outlier_prob\": 0.5, \"accuracy\": 0.9824755787849426, \"window_size\": 50}, {\"outlier_prob\": 0.6, \"accuracy\": 0.9768655300140381, \"window_size\": 50}, {\"outlier_prob\": 0.7, \"accuracy\": 0.9705906510353088, \"window_size\": 50}, {\"outlier_prob\": 0.8, \"accuracy\": 0.9605104327201843, \"window_size\": 50}, {\"outlier_prob\": 0.9, \"accuracy\": 0.9316745400428772, \"window_size\": 50}, {\"outlier_prob\": 1.0, \"accuracy\": 0.5029677152633667, \"window_size\": 50}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df_rnn).mark_line().encode(x='outlier_prob', y='accuracy', color='window_size:N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to windowed CNN, RNNs on windows also peform better with larger window sizes at higher outlier probabilities, which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see now how the tensorboard graphs look like. You can use those graphs as a reference when comparing them to the more complex models in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "815/815 [==============================] - 17s 18ms/step - loss: 0.4644 - binary_accuracy: 0.7438\n",
      "Epoch 2/5\n",
      "815/815 [==============================] - 14s 17ms/step - loss: 0.0785 - binary_accuracy: 0.9793\n",
      "Epoch 3/5\n",
      "815/815 [==============================] - 13s 16ms/step - loss: 0.0625 - binary_accuracy: 0.9841\n",
      "Epoch 4/5\n",
      "815/815 [==============================] - 14s 17ms/step - loss: 0.0563 - binary_accuracy: 0.9860\n",
      "Epoch 5/5\n",
      "815/815 [==============================] - 14s 17ms/step - loss: 0.0525 - binary_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b3e2910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "from datetime import datetime\n",
    "!rm -rf ./logs/\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "dataset = Dataset.generate(train_outlier_prob=0.10, n_samples=100)\n",
    "\n",
    "get_rnn_model().fit(\n",
    "    x=dataset.to_window_tfds(window_size=20).batch(100),\n",
    "    epochs=5,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
