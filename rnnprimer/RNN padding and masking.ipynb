{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Primer\n",
    "## Part 2: Padding and masking\n",
    "\n",
    "In real world, we typically won't have time series samples of the same length. For example, one user was tracking his movement of 30 minutes, another for 1 hour, another for 10 minutes, etc.\n",
    "\n",
    "In the previous notebook, we generated samples of the same length. To accomodate samples of different lenght, we need to use the techniques called **padding** and **masking**. Let's see how it's done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import altair as alt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from rnnprimer.datagen import generate_sample, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we adapt our sample generation function such that it can generate a variable number of train segments. For simplicity, we keep the train/walk split at 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4f478a122f3545f79f94c4b802d70ef1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4f478a122f3545f79f94c4b802d70ef1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4f478a122f3545f79f94c4b802d70ef1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-fc6a47308de03bfccf6b0de88dc80c17\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"time step\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"speed\"}}, \"title\": \"Sample without outliers\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-fc6a47308de03bfccf6b0de88dc80c17\": [{\"time step\": 0, \"speed\": 5.0}, {\"time step\": 1, \"speed\": 5.0}, {\"time step\": 2, \"speed\": 5.0}, {\"time step\": 3, \"speed\": 5.0}, {\"time step\": 4, \"speed\": 5.0}, {\"time step\": 5, \"speed\": 5.0}, {\"time step\": 6, \"speed\": 5.0}, {\"time step\": 7, \"speed\": 5.0}, {\"time step\": 8, \"speed\": 5.0}, {\"time step\": 9, \"speed\": 5.0}, {\"time step\": 10, \"speed\": 5.0}, {\"time step\": 11, \"speed\": 5.0}, {\"time step\": 12, \"speed\": 5.0}, {\"time step\": 13, \"speed\": 5.0}, {\"time step\": 14, \"speed\": 5.0}, {\"time step\": 15, \"speed\": 5.0}, {\"time step\": 16, \"speed\": 5.0}, {\"time step\": 17, \"speed\": 5.0}, {\"time step\": 18, \"speed\": 5.0}, {\"time step\": 19, \"speed\": 5.0}, {\"time step\": 20, \"speed\": 5.0}, {\"time step\": 21, \"speed\": 5.0}, {\"time step\": 22, \"speed\": 5.0}, {\"time step\": 23, \"speed\": 5.0}, {\"time step\": 24, \"speed\": 5.0}, {\"time step\": 25, \"speed\": 5.0}, {\"time step\": 26, \"speed\": 5.0}, {\"time step\": 27, \"speed\": 5.0}, {\"time step\": 28, \"speed\": 5.0}, {\"time step\": 29, \"speed\": 5.0}, {\"time step\": 30, \"speed\": 5.0}, {\"time step\": 31, \"speed\": 5.0}, {\"time step\": 32, \"speed\": 5.0}, {\"time step\": 33, \"speed\": 5.0}, {\"time step\": 34, \"speed\": 5.0}, {\"time step\": 35, \"speed\": 5.0}, {\"time step\": 36, \"speed\": 5.0}, {\"time step\": 37, \"speed\": 5.0}, {\"time step\": 38, \"speed\": 5.0}, {\"time step\": 39, \"speed\": 5.0}, {\"time step\": 40, \"speed\": 5.0}, {\"time step\": 41, \"speed\": 5.0}, {\"time step\": 42, \"speed\": 5.0}, {\"time step\": 43, \"speed\": 5.0}, {\"time step\": 44, \"speed\": 5.0}, {\"time step\": 45, \"speed\": 5.0}, {\"time step\": 46, \"speed\": 5.0}, {\"time step\": 47, \"speed\": 5.0}, {\"time step\": 48, \"speed\": 5.0}, {\"time step\": 49, \"speed\": 5.0}, {\"time step\": 50, \"speed\": 5.0}, {\"time step\": 51, \"speed\": 5.0}, {\"time step\": 52, \"speed\": 5.0}, {\"time step\": 53, \"speed\": 5.0}, {\"time step\": 54, \"speed\": 5.0}, {\"time step\": 55, \"speed\": 5.0}, {\"time step\": 56, \"speed\": 5.0}, {\"time step\": 57, \"speed\": 5.0}, {\"time step\": 58, \"speed\": 5.0}, {\"time step\": 59, \"speed\": 5.0}, {\"time step\": 60, \"speed\": 5.0}, {\"time step\": 61, \"speed\": 5.0}, {\"time step\": 62, \"speed\": 5.0}, {\"time step\": 63, \"speed\": 5.0}, {\"time step\": 64, \"speed\": 5.0}, {\"time step\": 65, \"speed\": 5.0}, {\"time step\": 66, \"speed\": 5.0}, {\"time step\": 67, \"speed\": 5.0}, {\"time step\": 68, \"speed\": 5.0}, {\"time step\": 69, \"speed\": 5.0}, {\"time step\": 70, \"speed\": 5.0}, {\"time step\": 71, \"speed\": 5.0}, {\"time step\": 72, \"speed\": 5.0}, {\"time step\": 73, \"speed\": 5.0}, {\"time step\": 74, \"speed\": 5.0}, {\"time step\": 75, \"speed\": 5.0}, {\"time step\": 76, \"speed\": 5.0}, {\"time step\": 77, \"speed\": 5.0}, {\"time step\": 78, \"speed\": 5.0}, {\"time step\": 79, \"speed\": 5.0}, {\"time step\": 80, \"speed\": 5.0}, {\"time step\": 81, \"speed\": 5.0}, {\"time step\": 82, \"speed\": 5.0}, {\"time step\": 83, \"speed\": 5.0}, {\"time step\": 84, \"speed\": 5.0}, {\"time step\": 85, \"speed\": 5.0}, {\"time step\": 86, \"speed\": 5.0}, {\"time step\": 87, \"speed\": 5.0}, {\"time step\": 88, \"speed\": 5.0}, {\"time step\": 89, \"speed\": 5.0}, {\"time step\": 90, \"speed\": 5.0}, {\"time step\": 91, \"speed\": 5.0}, {\"time step\": 92, \"speed\": 5.0}, {\"time step\": 93, \"speed\": 5.0}, {\"time step\": 94, \"speed\": 5.0}, {\"time step\": 95, \"speed\": 5.0}, {\"time step\": 96, \"speed\": 5.0}, {\"time step\": 97, \"speed\": 5.0}, {\"time step\": 98, \"speed\": 5.0}, {\"time step\": 99, \"speed\": 5.0}, {\"time step\": 100, \"speed\": 0.0}, {\"time step\": 101, \"speed\": 5.2631578947368425}, {\"time step\": 102, \"speed\": 10.526315789473685}, {\"time step\": 103, \"speed\": 15.789473684210526}, {\"time step\": 104, \"speed\": 21.05263157894737}, {\"time step\": 105, \"speed\": 26.31578947368421}, {\"time step\": 106, \"speed\": 31.57894736842105}, {\"time step\": 107, \"speed\": 36.8421052631579}, {\"time step\": 108, \"speed\": 42.10526315789474}, {\"time step\": 109, \"speed\": 47.36842105263158}, {\"time step\": 110, \"speed\": 52.63157894736842}, {\"time step\": 111, \"speed\": 57.89473684210526}, {\"time step\": 112, \"speed\": 63.1578947368421}, {\"time step\": 113, \"speed\": 68.42105263157895}, {\"time step\": 114, \"speed\": 73.6842105263158}, {\"time step\": 115, \"speed\": 78.94736842105263}, {\"time step\": 116, \"speed\": 84.21052631578948}, {\"time step\": 117, \"speed\": 89.47368421052632}, {\"time step\": 118, \"speed\": 94.73684210526316}, {\"time step\": 119, \"speed\": 100.0}, {\"time step\": 120, \"speed\": 100.0}, {\"time step\": 121, \"speed\": 100.0}, {\"time step\": 122, \"speed\": 100.0}, {\"time step\": 123, \"speed\": 100.0}, {\"time step\": 124, \"speed\": 100.0}, {\"time step\": 125, \"speed\": 100.0}, {\"time step\": 126, \"speed\": 100.0}, {\"time step\": 127, \"speed\": 100.0}, {\"time step\": 128, \"speed\": 100.0}, {\"time step\": 129, \"speed\": 100.0}, {\"time step\": 130, \"speed\": 100.0}, {\"time step\": 131, \"speed\": 100.0}, {\"time step\": 132, \"speed\": 100.0}, {\"time step\": 133, \"speed\": 100.0}, {\"time step\": 134, \"speed\": 100.0}, {\"time step\": 135, \"speed\": 100.0}, {\"time step\": 136, \"speed\": 100.0}, {\"time step\": 137, \"speed\": 100.0}, {\"time step\": 138, \"speed\": 100.0}, {\"time step\": 139, \"speed\": 100.0}, {\"time step\": 140, \"speed\": 100.0}, {\"time step\": 141, \"speed\": 100.0}, {\"time step\": 142, \"speed\": 100.0}, {\"time step\": 143, \"speed\": 100.0}, {\"time step\": 144, \"speed\": 100.0}, {\"time step\": 145, \"speed\": 100.0}, {\"time step\": 146, \"speed\": 100.0}, {\"time step\": 147, \"speed\": 100.0}, {\"time step\": 148, \"speed\": 100.0}, {\"time step\": 149, \"speed\": 100.0}, {\"time step\": 150, \"speed\": 100.0}, {\"time step\": 151, \"speed\": 100.0}, {\"time step\": 152, \"speed\": 100.0}, {\"time step\": 153, \"speed\": 100.0}, {\"time step\": 154, \"speed\": 100.0}, {\"time step\": 155, \"speed\": 100.0}, {\"time step\": 156, \"speed\": 100.0}, {\"time step\": 157, \"speed\": 100.0}, {\"time step\": 158, \"speed\": 100.0}, {\"time step\": 159, \"speed\": 100.0}, {\"time step\": 160, \"speed\": 100.0}, {\"time step\": 161, \"speed\": 100.0}, {\"time step\": 162, \"speed\": 100.0}, {\"time step\": 163, \"speed\": 100.0}, {\"time step\": 164, \"speed\": 100.0}, {\"time step\": 165, \"speed\": 100.0}, {\"time step\": 166, \"speed\": 100.0}, {\"time step\": 167, \"speed\": 100.0}, {\"time step\": 168, \"speed\": 100.0}, {\"time step\": 169, \"speed\": 100.0}, {\"time step\": 170, \"speed\": 100.0}, {\"time step\": 171, \"speed\": 100.0}, {\"time step\": 172, \"speed\": 100.0}, {\"time step\": 173, \"speed\": 100.0}, {\"time step\": 174, \"speed\": 100.0}, {\"time step\": 175, \"speed\": 100.0}, {\"time step\": 176, \"speed\": 100.0}, {\"time step\": 177, \"speed\": 100.0}, {\"time step\": 178, \"speed\": 100.0}, {\"time step\": 179, \"speed\": 100.0}, {\"time step\": 180, \"speed\": 100.0}, {\"time step\": 181, \"speed\": 94.73684210526316}, {\"time step\": 182, \"speed\": 89.47368421052632}, {\"time step\": 183, \"speed\": 84.21052631578948}, {\"time step\": 184, \"speed\": 78.94736842105263}, {\"time step\": 185, \"speed\": 73.6842105263158}, {\"time step\": 186, \"speed\": 68.42105263157895}, {\"time step\": 187, \"speed\": 63.1578947368421}, {\"time step\": 188, \"speed\": 57.89473684210526}, {\"time step\": 189, \"speed\": 52.63157894736842}, {\"time step\": 190, \"speed\": 47.36842105263158}, {\"time step\": 191, \"speed\": 42.10526315789474}, {\"time step\": 192, \"speed\": 36.8421052631579}, {\"time step\": 193, \"speed\": 31.57894736842105}, {\"time step\": 194, \"speed\": 26.31578947368421}, {\"time step\": 195, \"speed\": 21.05263157894737}, {\"time step\": 196, \"speed\": 15.789473684210526}, {\"time step\": 197, \"speed\": 10.526315789473685}, {\"time step\": 198, \"speed\": 5.2631578947368425}, {\"time step\": 199, \"speed\": 0.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = generate_sample(total_train_seg_n=1)\n",
    "fig = sample.get_figure()\n",
    "fig.properties(title=\"Sample without outliers\", width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a dataset where a size of a train segment is a random integer from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-25e6469302fd478fb7a1b6463debe04c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-25e6469302fd478fb7a1b6463debe04c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-25e6469302fd478fb7a1b6463debe04c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-8cdfff31936b5ae5a81216e7969fe384\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"bin\": true, \"field\": \"# of timesteps\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-8cdfff31936b5ae5a81216e7969fe384\": [{\"# of timesteps\": 800}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 400}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 200}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 400}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 400}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 400}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 600}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 600}, {\"# of timesteps\": 600}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 600}, {\"# of timesteps\": 400}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 200}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 200}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 400}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 600}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 600}, {\"# of timesteps\": 200}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 400}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 200}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 800}, {\"# of timesteps\": 200}, {\"# of timesteps\": 200}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 800}, {\"# of timesteps\": 200}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1200}, {\"# of timesteps\": 600}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 800}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 800}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 200}, {\"# of timesteps\": 800}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1600}, {\"# of timesteps\": 600}, {\"# of timesteps\": 1000}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 1800}, {\"# of timesteps\": 1400}, {\"# of timesteps\": 2000}, {\"# of timesteps\": 800}, {\"# of timesteps\": 1800}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seg_n = lambda: np.random.randint(1,11)\n",
    "dataset = Dataset.generate(train_outlier_prob=0, n_samples=100, total_train_seg=train_seg_n)\n",
    "sample_size_df = pd.DataFrame([len(s) for s in dataset.samples], columns=['# of timesteps'])\n",
    "alt.Chart(sample_size_df).mark_bar().encode(\n",
    "    alt.X(\"# of timesteps:Q\", bin=True),\n",
    "    y='count()',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 train segment is 100 timesteps + 100 timesteps for walk, so 200 timesteps in total. We can see that now we have a more or less uniform distribution of different sample lenghts in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset.to_tfds():\n",
    "    features, labels = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.05]\n",
      " [ 0.05]\n",
      " [ 0.05]\n",
      " ...\n",
      " [-1.  ]\n",
      " [-1.  ]\n",
      " [-1.  ]], shape=(1600, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last elements of the first feature vector were set to -1 and the total size is 1600 elements. This means that in this batch there is a sample with a maximum of 1600 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.1,\n",
    "        decay_steps=100,\n",
    "        decay_rate=0.5)\n",
    "\n",
    "rnn_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Masking(mask_value=np.array([-1])),\n",
    "        tf.keras.layers.GRU(8, return_sequences=True),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "rnn_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4486 - binary_accuracy: 0.5780\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1220 - binary_accuracy: 0.9007\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.0492 - binary_accuracy: 0.9883\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.0398 - binary_accuracy: 0.9905\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.0352 - binary_accuracy: 0.9917\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.1856 - binary_accuracy: 0.8458\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 4s 899ms/step - loss: 0.0399 - binary_accuracy: 0.9903\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.0350 - binary_accuracy: 0.9911\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.0316 - binary_accuracy: 0.9922\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.0290 - binary_accuracy: 0.9926\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 0.0278 - binary_accuracy: 0.9934\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.0260 - binary_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 4s 882ms/step - loss: 0.0257 - binary_accuracy: 0.9941\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.0231 - binary_accuracy: 0.9947\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.0242 - binary_accuracy: 0.9945\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.0258 - binary_accuracy: 0.9933\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 4s 824ms/step - loss: 0.0215 - binary_accuracy: 0.9953\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.0216 - binary_accuracy: 0.9951\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.0221 - binary_accuracy: 0.9951\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.0228 - binary_accuracy: 0.9943\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.0197 - binary_accuracy: 0.9959\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 4s 858ms/step - loss: 0.0196 - binary_accuracy: 0.9960\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.0213 - binary_accuracy: 0.9953\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.0179 - binary_accuracy: 0.9962\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.0173 - binary_accuracy: 0.9966\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.0208 - binary_accuracy: 0.9957\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 4s 842ms/step - loss: 0.0163 - binary_accuracy: 0.9969\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 4s 839ms/step - loss: 0.0183 - binary_accuracy: 0.9961\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.0162 - binary_accuracy: 0.9970\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.0198 - binary_accuracy: 0.9949\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.0158 - binary_accuracy: 0.9966\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 5s 921ms/step - loss: 0.0147 - binary_accuracy: 0.9971\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 4s 882ms/step - loss: 0.0142 - binary_accuracy: 0.9971\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.0143 - binary_accuracy: 0.9971\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.0136 - binary_accuracy: 0.9970\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 4s 874ms/step - loss: 0.0136 - binary_accuracy: 0.9970\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.0126 - binary_accuracy: 0.9970\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 5s 950ms/step - loss: 0.0135 - binary_accuracy: 0.9967\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.0119 - binary_accuracy: 0.9970\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0122 - binary_accuracy: 0.9972\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.0115 - binary_accuracy: 0.9977\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 4s 878ms/step - loss: 0.0124 - binary_accuracy: 0.9969\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 4s 843ms/step - loss: 0.0110 - binary_accuracy: 0.9980\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.0112 - binary_accuracy: 0.9979\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 4s 888ms/step - loss: 0.0113 - binary_accuracy: 0.9979\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.0106 - binary_accuracy: 0.9980\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 5s 907ms/step - loss: 0.0109 - binary_accuracy: 0.9980\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 4s 866ms/step - loss: 0.0107 - binary_accuracy: 0.9980\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.0108 - binary_accuracy: 0.9980\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.0110 - binary_accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b1e8bae85995629\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b1e8bae85995629\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "!rm -rf ./logs/\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "rnn_model.fit(\n",
    "    x=dataset.to_tfds(),\n",
    "    epochs=50,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.tensorflow.org/guide/keras/masking_and_padding for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
