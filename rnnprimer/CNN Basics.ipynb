{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification with Neural Networks\n",
    "## Part 3: Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from rnnprimer.datagen import generate_sample, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a standard CNN architecture based on [this post](https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/) with two Conv1D layers and a single output layer for binary classification.\n",
    "\n",
    "The learning rate is adjusted with a schedule for faster convergence given our simple data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.01,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.5)\n",
    "\n",
    "def get_cnn_model(n_features, n_timesteps):\n",
    "    cnn_model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Reshape((n_timesteps, n_features)),\n",
    "            tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)),\n",
    "            tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.MaxPool1D(pool_size=1),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(20, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cnn_model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule),\n",
    "            metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "    )\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn = []\n",
    "for outlier_prob in (0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0):\n",
    "    print(outlier_prob)\n",
    "    n_timesteps=5\n",
    "    dataset = Dataset.generate(train_outlier_prob=outlier_prob, n_samples=100)\n",
    "    model = get_cnn_model(n_features=1, n_timesteps=n_timesteps)\n",
    "\n",
    "    model.fit(\n",
    "        x=dataset.to_cnn_tfds(n_timesteps, batch_size=200),\n",
    "        epochs=10,\n",
    "        verbose=0\n",
    "    )\n",
    "    dataset = Dataset.generate(train_outlier_prob=outlier_prob, n_samples=20)\n",
    "    res = model.evaluate(dataset.to_cnn_tfds(n_timesteps), verbose=0)\n",
    "    data_cnn.append({'outlier_prob': outlier_prob, 'accuracy': res[1]})\n",
    "    \n",
    "df_cnn = pd.DataFrame(data_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-e2f2949ccf214923928112317af048e8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e2f2949ccf214923928112317af048e8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e2f2949ccf214923928112317af048e8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-948c9e6f4e503c4322bfa8c041a6b9c2\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"outlier_prob\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"accuracy\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-948c9e6f4e503c4322bfa8c041a6b9c2\": [{\"outlier_prob\": 0.01, \"accuracy\": 0.9998493790626526}, {\"outlier_prob\": 0.05, \"accuracy\": 0.9994980096817017}, {\"outlier_prob\": 0.1, \"accuracy\": 0.999146580696106}, {\"outlier_prob\": 0.2, \"accuracy\": 0.9967871308326721}, {\"outlier_prob\": 0.3, \"accuracy\": 0.9942771196365356}, {\"outlier_prob\": 0.4, \"accuracy\": 0.98574298620224}, {\"outlier_prob\": 0.5, \"accuracy\": 0.9765059947967529}, {\"outlier_prob\": 0.6, \"accuracy\": 0.9475903511047363}, {\"outlier_prob\": 0.7, \"accuracy\": 0.9041666388511658}, {\"outlier_prob\": 0.8, \"accuracy\": 0.8280622363090515}, {\"outlier_prob\": 0.9, \"accuracy\": 0.6940261125564575}, {\"outlier_prob\": 1.0, \"accuracy\": 0.5020080208778381}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df_cnn).mark_line().encode(x='outlier_prob', y='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for RNN, let's see how the tensorboard graphs look like for CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "996/996 [==============================] - 31s 31ms/step - loss: 0.0754 - binary_accuracy: 0.9742\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 31s 31ms/step - loss: 0.0102 - binary_accuracy: 0.9968\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 30s 30ms/step - loss: 0.0076 - binary_accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 31s 31ms/step - loss: 0.0067 - binary_accuracy: 0.9979\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 38s 38ms/step - loss: 0.0064 - binary_accuracy: 0.9980\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 39s 39ms/step - loss: 0.0063 - binary_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 37s 37ms/step - loss: 0.0061 - binary_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 37s 37ms/step - loss: 0.0057 - binary_accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 37s 37ms/step - loss: 0.0065 - binary_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 33s 33ms/step - loss: 0.0066 - binary_accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8775), started 2 days, 22:01:58 ago. (Use '!kill 8775' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7dd25954178434cb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7dd25954178434cb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "from datetime import datetime\n",
    "!rm -rf ./logs/\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "dataset = Dataset.generate(n_samples=200)\n",
    "\n",
    "get_cnn_model(n_features=1, n_timesteps=5).fit(\n",
    "    x=dataset.to_cnn_tfds(n_timesteps, batch_size=200),\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see what effect has the **window size** on the network performance, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
